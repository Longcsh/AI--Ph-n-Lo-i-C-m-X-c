# ==========================================================
# train_models/export_error_analysis.py
# PhÃ¢n tÃ­ch lá»—i dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh PhoBERT-base-v2 (phiÃªn báº£n cÃ³ log)
# ==========================================================

import os, json, pandas as pd, torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import classification_report, confusion_matrix

# ===== 1. ÄÆ°á»ng dáº«n =====
BASE = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA = os.path.join(BASE, "data", "data_balanced.csv")
MODEL_PATH = os.path.join(BASE, "models", "phobert_base_v2_cpu_final")
REPORTS = os.path.join(BASE, "reports")
os.makedirs(REPORTS, exist_ok=True)

print("ğŸ“‚ Äang táº£i dá»¯ liá»‡u vÃ  mÃ´ hÃ¬nh PhoBERT-base-v2...")

# ===== 2. Load dá»¯ liá»‡u =====
df = pd.read_csv(DATA).dropna(subset=["content", "label"])
label2id = {lbl: i for i, lbl in enumerate(sorted(df["label"].unique()))}
id2label = {v: k for k, v in label2id.items()}
df["label_id"] = df["label"].map(label2id)

# Chá»n 10% Ä‘á»ƒ test
test_df = df.sample(frac=0.1, random_state=42).reset_index(drop=True)
print(f"âœ… Táº£i {len(test_df)} máº«u test Ä‘á»ƒ phÃ¢n tÃ­ch lá»—i")

# ===== 3. Load model PhoBERT Ä‘Ã£ fine-tuned =====
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, use_fast=False)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
device = torch.device("cpu")
model.to(device)
model.eval()

# ===== 4. HÃ m dá»± Ä‘oÃ¡n =====
def predict_batch(texts, batch_size=16):
    preds_all = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        inputs = tokenizer(batch, truncation=True, padding=True, max_length=128, return_tensors="pt")
        inputs = {k: v.to(device) for k, v in inputs.items()}
        with torch.no_grad():
            outputs = model(**inputs)
            preds = torch.argmax(outputs.logits, dim=1)
            preds_all.extend(preds.cpu().numpy())
        print(f"   ğŸ”¹ Batch {i//batch_size + 1}/{len(texts)//batch_size + 1} done")
    return preds_all

# ===== 5. Thá»±c hiá»‡n dá»± Ä‘oÃ¡n =====
print("ğŸ¤– Äang dá»± Ä‘oÃ¡n trÃªn táº­p test...")
test_df["pred_id"] = predict_batch(test_df["content"].tolist())
test_df["pred_label"] = test_df["pred_id"].map(id2label)
test_df["true_label"] = test_df["label_id"].map(id2label)

# ===== 6. Táº¡o báº£ng lá»—i =====
errors = test_df[test_df["pred_label"] != test_df["true_label"]][["content", "true_label", "pred_label"]]
errors_path = os.path.join(REPORTS, "error_analysis.csv")
errors.to_csv(errors_path, index=False, encoding="utf-8-sig")

# ===== 7. LÆ°u bÃ¡o cÃ¡o Markdown =====
md_path = os.path.join(REPORTS, "error_analysis.md")
rep = classification_report(test_df["true_label"], test_df["pred_label"], target_names=sorted(label2id.keys()))

with open(md_path, "w", encoding="utf-8") as f:
    f.write("# ğŸ” PhÃ¢n tÃ­ch lá»—i PhoBERT-base-v2\n\n")
    f.write(rep + "\n\n")
    f.write(f"Tá»•ng sá»‘ máº«u test: {len(test_df)}\n")
    f.write(f"Sá»‘ lá»—i: {len(errors)} ({len(errors)/len(test_df)*100:.2f}%)\n\n")
    f.write("### ğŸ§© Top 5 lá»—i tiÃªu biá»ƒu:\n")
    for i, row in errors.head(5).iterrows():
        f.write(f"- **VÄƒn báº£n:** {row['content'][:100]}...\n")
        f.write(f"  - Thá»±c táº¿: {row['true_label']}\n")
        f.write(f"  - Dá»± Ä‘oÃ¡n: {row['pred_label']}\n\n")

# ===== 8. Káº¿t quáº£ =====
print("\nâœ… PhÃ¢n tÃ­ch lá»—i hoÃ n táº¥t!")
print(f"ğŸ“Š Tá»•ng sá»‘ máº«u test: {len(test_df)}")
print(f"âŒ Sá»‘ máº«u dá»± Ä‘oÃ¡n sai: {len(errors)} ({len(errors)/len(test_df)*100:.2f}%)")
print(f"ğŸ“ CSV: {errors_path}")
print(f"ğŸ“ Markdown: {md_path}")
